{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8f4d1c8cbc954ddeaf3a83fa56a1030e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ffc0b8f20c54e5ea38626784137ebaf","IPY_MODEL_6fe1769d65b5423581144802f0615889","IPY_MODEL_7a5e6a6f6078492984a71848cecb489b"],"layout":"IPY_MODEL_b1a306c62b4f46a1beaad7db439530f0"}},"5ffc0b8f20c54e5ea38626784137ebaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cdab535a1be494fb295e0c01860f24f","placeholder":"​","style":"IPY_MODEL_5bef1616dea7472e9667d15b8d82cef6","value":"Loading checkpoint shards: 100%"}},"6fe1769d65b5423581144802f0615889":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98398d43a6c4004ba0bab87a5cb4d46","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c13f13ece2f4482b9d11b152f77c5a9","value":2}},"7a5e6a6f6078492984a71848cecb489b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ecaecdfc94b46958b4d0c82357c895b","placeholder":"​","style":"IPY_MODEL_7ff7836994ad46c3b3cc7ddd8d1cfcf1","value":" 2/2 [00:35&lt;00:00, 15.00s/it]"}},"b1a306c62b4f46a1beaad7db439530f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cdab535a1be494fb295e0c01860f24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bef1616dea7472e9667d15b8d82cef6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a98398d43a6c4004ba0bab87a5cb4d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c13f13ece2f4482b9d11b152f77c5a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ecaecdfc94b46958b4d0c82357c895b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ff7836994ad46c3b3cc7ddd8d1cfcf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install and import the necessary libraries\n!pip install -q -U torch\n!pip install -q -U accelerate peft bitsandbytes transformers trl einops evaluate\n!pip install -q -U tqdm\n!pip install -q -U git+https://github.com/sissa-data-science/DADApy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMiBuGkA9hDF","outputId":"95f53b22-6c08-4fbb-d0a3-705f3e33d305","execution":{"iopub.status.busy":"2024-06-10T20:30:53.306188Z","iopub.execute_input":"2024-06-10T20:30:53.306907Z","iopub.status.idle":"2024-06-10T20:35:14.815263Z","shell.execute_reply.started":"2024-06-10T20:30:53.306869Z","shell.execute_reply":"2024-06-10T20:35:14.814073Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom datasets import load_from_disk\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nfrom tqdm import tqdm\nimport gc\nimport matplotlib.pyplot as plt\nfrom dadapy.data import Data\nimport numpy as np","metadata":{"id":"UNqKhvRl-Ac9","execution":{"iopub.status.busy":"2024-06-10T20:35:14.817538Z","iopub.execute_input":"2024-06-10T20:35:14.817841Z","iopub.status.idle":"2024-06-10T20:35:32.912082Z","shell.execute_reply.started":"2024-06-10T20:35:14.817813Z","shell.execute_reply":"2024-06-10T20:35:32.911121Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-10 20:35:22.923478: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-10 20:35:22.923589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-10 20:35:23.046049: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model\nbase_model = \"microsoft/phi-2\"\nnew_model = \"phi-2-medquad\"\n\n# Dataset\ndataset = load_dataset(\"prsdm/MedQuad-phi2-1k\", split=\"train\")\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"right\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rY8QvKBX-Afo","outputId":"18447acd-195e-4e2a-e7e9-bf4fe3654724","execution":{"iopub.status.busy":"2024-06-10T20:35:32.913405Z","iopub.execute_input":"2024-06-10T20:35:32.914531Z","iopub.status.idle":"2024-06-10T20:35:45.379883Z","shell.execute_reply.started":"2024-06-10T20:35:32.914496Z","shell.execute_reply":"2024-06-10T20:35:45.378977Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/274 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087f35dc104343c9802514393b1402eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad02a2607354664a7bcf8095dc35e7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"864c52fd070a45e8a0fad74e20bcdf0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f6a6d6fa12a4e9e8d6b5e823ea325d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865c30bbba934ee9aa7e114609b08dc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d98960c84454cc8a2eed8afdc41f4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5976130764bc467da025cb6b64b29b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e383ef8ad1d48f7bc4d495cafe7c738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7348e9375b248b288051e9dd66e15bd"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# training samples\ntrain_dataset = dataset.select(range(800))","metadata":{"id":"KOAGY1tS-AiO","execution":{"iopub.status.busy":"2024-06-10T20:35:45.381127Z","iopub.execute_input":"2024-06-10T20:35:45.381499Z","iopub.status.idle":"2024-06-10T20:35:45.388351Z","shell.execute_reply.started":"2024-06-10T20:35:45.381464Z","shell.execute_reply":"2024-06-10T20:35:45.387481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Function that tokenizes the text\ndef tokenize(rows):\n    # Retrieve Text\n    if rows[\"text\"][0] is None:\n        text = \"\"\n    else:\n        text = rows[\"text\"][0].replace('\"', r'\\\"')\n\n    # Tokenize\n    encoded = tokenizer(\n          text,\n          add_special_tokens=True,\n          max_length=260,\n          return_token_type_ids=False,\n          return_attention_mask=True,\n          return_tensors='pt',\n        ).to(\"cuda\")\n    return encoded","metadata":{"id":"uoJd7wVg-Akn","execution":{"iopub.status.busy":"2024-06-10T20:35:45.390736Z","iopub.execute_input":"2024-06-10T20:35:45.391065Z","iopub.status.idle":"2024-06-10T20:35:45.397187Z","shell.execute_reply.started":"2024-06-10T20:35:45.391041Z","shell.execute_reply":"2024-06-10T20:35:45.396410Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Applying tokenization to the dataset\ntokenized_dataset = train_dataset.map(tokenize,\n                                batched=True,\n                                batch_size=1,\n                                remove_columns=[\"text\"])","metadata":{"id":"3jrqKhgQ-Ana","execution":{"iopub.status.busy":"2024-06-10T20:35:45.398212Z","iopub.execute_input":"2024-06-10T20:35:45.398473Z","iopub.status.idle":"2024-06-10T20:35:48.573432Z","shell.execute_reply.started":"2024-06-10T20:35:45.398429Z","shell.execute_reply":"2024-06-10T20:35:48.572079Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b175de9a3d54d2eb7f9f0be7c3502e9"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    device_map={\"\": 0},\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8f4d1c8cbc954ddeaf3a83fa56a1030e","5ffc0b8f20c54e5ea38626784137ebaf","6fe1769d65b5423581144802f0615889","7a5e6a6f6078492984a71848cecb489b","b1a306c62b4f46a1beaad7db439530f0","2cdab535a1be494fb295e0c01860f24f","5bef1616dea7472e9667d15b8d82cef6","a98398d43a6c4004ba0bab87a5cb4d46","3c13f13ece2f4482b9d11b152f77c5a9","2ecaecdfc94b46958b4d0c82357c895b","7ff7836994ad46c3b3cc7ddd8d1cfcf1"]},"id":"_FFhfn3r-Apr","outputId":"a23fc25d-ea46-406c-e25e-70d329081fd6","execution":{"iopub.status.busy":"2024-06-10T20:35:48.574824Z","iopub.execute_input":"2024-06-10T20:35:48.575424Z","iopub.status.idle":"2024-06-10T20:36:13.003639Z","shell.execute_reply.started":"2024-06-10T20:35:48.575390Z","shell.execute_reply":"2024-06-10T20:36:13.002796Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a3bec8ccaa4edebdecc272b5612564"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7c17dd1b9144b28d966899d9ba41f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2f6a840e1649628569bc381ba5104b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e92655d89b549038f6d37a24bba1e8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ccd737b45d42879a44021abd198664"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66c1ceff42a4311971276f0e77108d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aeba0cdaf3b47429b81010c01a1b467"}},"metadata":{}}]},{"cell_type":"code","source":"# computing intrinsic dimentions\n# Constants\n\ntorch.cuda.empty_cache()\ngc.collect()\n\n# 250 total samples\nnum_data = 250\n\nbatches = 2\n\n# samples per batch\nbatch_data = num_data//batches\n\n# Samples per sub-batch within each batch\nper_batch = batch_data//batches\n\n# Number of sub-batches per batch\nnumber_batches = batch_data // per_batch\n\n# initializing intrinsic dimension lists for each batch\nintrinsic_dims = [[] for _ in range(batches)]\n\nfor x in range(batches):\n  torch.set_default_device(\"cuda\")\n\n  # Collect hidden layers\n  hidden_layers = []\n\n  # Collect hidden layers per batch\n  for batch in tqdm(range(number_batches)):\n    for i in range(per_batch):\n      # Extract inputs from the dataset using the tokenizer\n      index = batch * per_batch + i + x * batch_data\n      inputs = {k: torch.tensor(v).unsqueeze(0).to(\"cuda\") for k, v in tokenized_dataset[index].items()}\n\n      # Perform forward pass through the model\n      with torch.no_grad():\n          outputs = model(**inputs, output_hidden_states=True)\n\n      # Append the hidden states to the list\n      liste = list(map(lambda x: x.to('cpu'), outputs.hidden_states))\n      hidden_layers.append(liste)\n      del outputs, liste, inputs\n      torch.cuda.empty_cache()\n      gc.collect()\n\n\n  # Move back to CPU\n  torch.set_default_device(\"cpu\")\n\n  # Process hidden layers\n  hidden_layers_avg = []\n  n = len(hidden_layers[0])\n  for j in range(n):\n      avg_batch_layer = []\n      for i in range(number_batches * per_batch):\n          layer = hidden_layers[i][j].detach().cpu()\n          avg_batch_layer.append(torch.mean(layer.squeeze(dim=0), dim=0))\n      hidden_layers_avg.append(avg_batch_layer)\n\n  # Handle empty tensors\n  for layer in hidden_layers_avg:\n      for idx, tensor in enumerate(layer):\n          if tensor.shape == torch.Size([]):\n              print(\"Encountered empty tensor. Filling with zeros.\")\n              layer[idx] = torch.zeros(2560)\n\n\n  # Stack hidden layers\n  hidden_layers_stacked = [torch.stack(layer) for layer in hidden_layers_avg]\n  hidden_layers_stacked = torch.stack(hidden_layers_stacked)\n\n  del hidden_layers, hidden_layers_avg\n  gc.collect()\n\n  # Compute intrinsic dimensions\n  for i in range(n):\n      X = hidden_layers_stacked[i].numpy()\n      data = Data(X)\n      data.remove_identical_points()\n      id_list_2NN, _, _ = data.return_id_scaling_2NN()\n      intrinsic_dims[x].append(id_list_2NN[1])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tzPndd6-9Pj","outputId":"df25a956-b6d9-4092-d764-b4a16bf27763","execution":{"iopub.status.busy":"2024-06-10T20:36:13.005584Z","iopub.execute_input":"2024-06-10T20:36:13.006224Z","iopub.status.idle":"2024-06-10T20:39:25.645456Z","shell.execute_reply.started":"2024-06-10T20:36:13.006188Z","shell.execute_reply":"2024-06-10T20:39:25.644706Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [01:33<00:00, 46.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"No identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [01:30<00:00, 45.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"No identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\nNo identical identical points were found\n","output_type":"stream"}]},{"cell_type":"code","source":"# calculating mean and standard deviation of intrinsic dimensions for each layer\n\n# ids = len(intrinsic_dims)\n\n# # total layers\n# n = len(intrinsic_dims[0])\n# mean = []\n# std = []\n\n# for i in range(n):\n#   layer_mean = np.mean([intrinsic_dims[0][i],intrinsic_dims[1][i],intrinsic_dims[2][i],intrinsic_dims[3][i],intrinsic_dims[4][i]])\n#   mean.append(layer_mean)\n#   layer_std = np.std([intrinsic_dims[0][i],intrinsic_dims[1][i],intrinsic_dims[2][i],intrinsic_dims[3][i],intrinsic_dims[4][i]])\n#   std.append(layer_std)","metadata":{"id":"RZ4iCqb0-9Uj","execution":{"iopub.status.busy":"2024-06-10T20:39:25.646654Z","iopub.execute_input":"2024-06-10T20:39:25.646933Z","iopub.status.idle":"2024-06-10T20:39:25.651485Z","shell.execute_reply.started":"2024-06-10T20:39:25.646910Z","shell.execute_reply":"2024-06-10T20:39:25.650500Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# calculating mean and standard deviation of intrinsic dimensions for each layer\nmean = np.mean(intrinsic_dims, axis=0)\nstd = np.std(intrinsic_dims, axis=0)","metadata":{"id":"GDJ1_jieoKyi","execution":{"iopub.status.busy":"2024-06-10T20:39:25.652571Z","iopub.execute_input":"2024-06-10T20:39:25.652849Z","iopub.status.idle":"2024-06-10T20:39:25.659972Z","shell.execute_reply.started":"2024-06-10T20:39:25.652816Z","shell.execute_reply":"2024-06-10T20:39:25.659173Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# each value in the array represent the mean of intrinsic dimension of the respective layer across \n# the number of batches taken\nmean","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWFobhjb-9XF","outputId":"e071069e-4419-4ed3-b86a-db919ddcd933","execution":{"iopub.status.busy":"2024-06-10T20:39:25.661072Z","iopub.execute_input":"2024-06-10T20:39:25.661668Z","iopub.status.idle":"2024-06-10T20:39:25.671118Z","shell.execute_reply.started":"2024-06-10T20:39:25.661638Z","shell.execute_reply":"2024-06-10T20:39:25.670205Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([11.81, 11.77, 12.15, 12.08, 12.09, 11.63, 10.59, 10.  ,  9.41,\n        9.51,  9.39,  9.57,  9.64,  9.54,  9.52,  9.67,  9.78,  9.91,\n        9.92,  9.51,  8.87,  8.79,  8.47,  8.01,  7.65,  7.29,  7.2 ,\n        7.29,  7.46,  8.15,  8.24,  7.93,  7.99])"},"metadata":{}}]},{"cell_type":"code","source":"# each value in the array represent the standard deviation of intrinsic dimension of the \n# respective layer across the number of batches taken\nstd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxQw-B2c-9Z0","outputId":"ebabfc8f-7784-48a5-fd42-f49995757518","execution":{"iopub.status.busy":"2024-06-10T20:39:25.672304Z","iopub.execute_input":"2024-06-10T20:39:25.672657Z","iopub.status.idle":"2024-06-10T20:39:25.680886Z","shell.execute_reply.started":"2024-06-10T20:39:25.672626Z","shell.execute_reply":"2024-06-10T20:39:25.680009Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0.57, 1.66, 1.72, 1.67, 1.22, 1.69, 1.31, 1.15, 1.16, 1.02, 1.09,\n       1.4 , 1.56, 1.59, 1.7 , 1.74, 1.8 , 1.75, 1.92, 1.78, 1.71, 1.56,\n       1.48, 1.38, 1.37, 1.29, 1.25, 1.24, 1.29, 1.51, 1.67, 1.18, 1.61])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"_sKr5RhXnzk1"},"execution_count":null,"outputs":[]}]}