## **LLM Experiments and Research**  

Research on optimizing Large Language Models (LLMs) through parameter-efficient fine-tuning, information geometry, intrinsic dimension analysis, truthfulness evaluation, and efficient large-scale GPU training.

### **Key Areas of Focus:**  

- **Fine-Tuning Innovations:**  
  Efficient tuning techniques such as LoRA, AdaLoRA, QLoRA, SoRA, and ALoRA.  

- **Intrinsic Dimension Analysis:**  
  Researching different intrinsic dimension estimators to optimize model complexity and improve fine-tuning efficiency.  

- **Entropy and Geometry Analysis:**  
  Understanding internal model representations to enhance model interpretability and performance.  

- **Truthfulness Assessment:**  
  Evaluating hallucinations and factual accuracy in LLM outputs.  

- **Training Efficiency:**  
  Optimizing large-scale experiments on GPU clusters.  
